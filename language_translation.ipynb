{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from data import TranslationDataset\n",
    "from rnn import RNN, RNNTools\n",
    "from transformers import Transformers, TransformersTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurable parameters, change as needed\n",
    "\n",
    "# set to true if loading existing model file, false if training a new model\n",
    "skip_training = True\n",
    "data_dir = 'data'\n",
    "rnn_model_save_path = 'models/rnn.pth'\n",
    "tra_model_save_path = 'models/transformers.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dirs if not existing\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device type: cpu\n"
     ]
    }
   ],
   "source": [
    "# additional settings, automatically selects cuda if available\n",
    "if skip_training:\n",
    "    device_type = 'cpu'\n",
    "elif torch.cuda.is_available():\n",
    "    device_type = 'cuda:0'\n",
    "else:\n",
    "    device_type = 'cpu'\n",
    "\n",
    "# set manually if needed e.g. device_type = 'cpu'\n",
    "print(\"Using device type:\", device_type)\n",
    "device = torch.device(device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentence pairs in the training set:  8682\n",
      "Number of sentence pairs in the test set:  2171\n"
     ]
    }
   ],
   "source": [
    "trainset = TranslationDataset(data_dir, train=True)\n",
    "testset = TranslationDataset(data_dir, train=False)\n",
    "print('Number of sentence pairs in the training set: ', len(trainset))\n",
    "print('Number of sentence pairs in the test set: ', len(testset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset=trainset, batch_size=64, shuffle=True, collate_fn=RNNTools.collate, pin_memory=True)\n",
    "testloader = DataLoader(dataset=testset, batch_size=64, shuffle=False, collate_fn=RNNTools.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(4489, 256)\n",
       "    (gru): GRU(256, 256)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(2925, 256)\n",
       "    (gru): GRU(256, 256)\n",
       "    (out): Linear(in_features=256, out_features=2925, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = RNN(trainset.input_lang.n_words, trainset.output_lang.n_words, embed_size=256, hidden_size=256)\n",
    "rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "    PADDING_VALUE = 0 \n",
    "    teacher_forcing_ratio = 0.5\n",
    "    num_epochs = 2\n",
    "\n",
    "    optimizer = torch.optim.Adam(rnn.parameters(), lr=0.001)    \n",
    "    criterion = nn.NLLLoss(ignore_index=PADDING_VALUE)\n",
    "    \n",
    "    rnn.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        total_data = 0\n",
    "        for src_seqs, src_seq_lengths, tgt_seqs in trainloader:\n",
    "            src_seqs, tgt_seqs = src_seqs.to(device), tgt_seqs.to(device)\n",
    "            \n",
    "            if torch.rand(1) < teacher_forcing_ratio:\n",
    "                teacher_forcing=True\n",
    "            else:\n",
    "                teacher_forcing=False\n",
    "            \n",
    "            # forward pass\n",
    "            outputs = rnn(src_seqs, tgt_seqs, src_seq_lengths, teacher_forcing)\n",
    "            loss = criterion(outputs.permute(0, 2, 1).to(device), tgt_seqs)\n",
    "            \n",
    "            # compute loss metric\n",
    "            total_loss += (loss.item() * src_seqs.shape[1])\n",
    "            total_data += src_seqs.shape[1]\n",
    "\n",
    "            # backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"epoch: {0} training loss: {1:.3f}\".format(epoch, total_loss/total_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "    torch.save(rnn.state_dict(), rnn_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN model loaded from: models/rnn.pth\n"
     ]
    }
   ],
   "source": [
    "if skip_training:\n",
    "    rnn.load_state_dict(torch.load(rnn_model_save_path, map_location=lambda storage, loc: storage))\n",
    "    print('RNN model loaded from: {}'.format(rnn_model_save_path))\n",
    "    rnn.to(device)\n",
    "    rnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnntools = RNNTools(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate test data:\n",
      "-----------------------------\n",
      "SRC: nous sommes des gagneurs .\n",
      "TGT: we re winners .\n",
      "OUT: we re classmates .\n",
      "\n",
      "SRC: je suis juste une fille normale .\n",
      "TGT: i m just an average girl .\n",
      "OUT: i m just a bad girl .\n",
      "\n",
      "SRC: je suis deja amoureux de tom .\n",
      "TGT: i m already in love with tom .\n",
      "OUT: i m much tom s mobile phone .\n",
      "\n",
      "SRC: elle est plus vieille que lui .\n",
      "TGT: she s older than him .\n",
      "OUT: she s taller than him .\n",
      "\n",
      "SRC: vous faites aller ca trop loin .\n",
      "TGT: you re carrying this too far .\n",
      "OUT: you re carrying this too far .\n",
      "\n",
      "SRC: nous ne sommes pas coupables .\n",
      "TGT: we re not guilty .\n",
      "OUT: we re not dressed .\n",
      "\n",
      "SRC: vous n y etes pas bonnes .\n",
      "TGT: you re not good at this .\n",
      "OUT: you re not good at this .\n",
      "\n",
      "SRC: nous sommes en train de mourir .\n",
      "TGT: we re dying .\n",
      "OUT: we re dying .\n",
      "\n",
      "SRC: il est tout sauf mort .\n",
      "TGT: he is all but dead .\n",
      "OUT: he is not tall .\n",
      "\n",
      "SRC: nous sommes debout .\n",
      "TGT: we re standing .\n",
      "OUT: we re ruined .\n",
      "\n",
      "SRC: je suis impatiente de te voir danser .\n",
      "TGT: i m looking forward to seeing you dance .\n",
      "OUT: i m looking forward to seeing you dance .\n",
      "\n",
      "SRC: tu es dedans jusqu au cou .\n",
      "TGT: you re in over your head .\n",
      "OUT: you re spoiling love that girl .\n",
      "\n",
      "SRC: tu n es pas occupe maintenant si ?\n",
      "TGT: you aren t busy now are you ?\n",
      "OUT: you re not a millionaire are you ?\n",
      "\n",
      "SRC: je suis trop vieux pour toi .\n",
      "TGT: i m too old for you .\n",
      "OUT: i m too old for you .\n",
      "\n",
      "SRC: elle est aimee de ses amies .\n",
      "TGT: she s loved by her friends .\n",
      "OUT: she is devoted on her wife .\n",
      "\n",
      "SRC: je crains que nous ayons un probleme .\n",
      "TGT: i m afraid we have a problem .\n",
      "OUT: i m afraid we have a pioneer .\n",
      "\n",
      "SRC: je n en suis plus aussi certain .\n",
      "TGT: i m not so sure anymore .\n",
      "OUT: i m not so sure anymore .\n",
      "\n",
      "SRC: je suis en train de boire une biere .\n",
      "TGT: i m drinking a beer .\n",
      "OUT: i am drinking a letter .\n",
      "\n",
      "SRC: nous allons bien .\n",
      "TGT: we re fine .\n",
      "OUT: we re going back .\n",
      "\n",
      "SRC: je ne fais que mon devoir .\n",
      "TGT: i m only doing my duty .\n",
      "OUT: i m not doing my job .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Translate test data:')\n",
    "print('-----------------------------')\n",
    "pad_src_seqs, src_seq_lengths, pad_tgt_seqs = next(iter(testloader))\n",
    "out_seqs = rnntools.translate(rnn, pad_src_seqs, src_seq_lengths)\n",
    "\n",
    "for i in random.sample(range(0, 64), 20):\n",
    "    print('SRC:', rnntools.seq_to_string(pad_src_seqs[:,i], testset.input_lang))\n",
    "    print('TGT:', rnntools.seq_to_string(pad_tgt_seqs[:,i], testset.output_lang))\n",
    "    print('OUT:', rnntools.seq_to_string(out_seqs[:,i], testset.output_lang))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score on training data: 96.69817090034485\n",
      "BLEU score on test data: 47.73730933666229\n"
     ]
    }
   ],
   "source": [
    "score = rnntools.compute_bleu_score(rnn, trainloader, trainset.output_lang)\n",
    "print(f'BLEU score on training data: {score*100}')\n",
    "score = rnntools.compute_bleu_score(rnn, testloader, trainset.output_lang)\n",
    "print(f'BLEU score on test data: {score*100}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset=trainset, batch_size=64, shuffle=True, collate_fn=TransformersTools.collate, pin_memory=True)\n",
    "testloader = DataLoader(dataset=testset, batch_size=64, shuffle=False, collate_fn=TransformersTools.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformers(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(4489, 256, padding_idx=0)\n",
       "    (positional_encoding): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder_blocks): ModuleList(\n",
       "      (0-2): 3 x EncoderBlock(\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): Dropout(p=0.1, inplace=False)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(2925, 256, padding_idx=0)\n",
       "    (positional_encoding): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0-2): 3 x DecoderBlock(\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (enc_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): Dropout(p=0.1, inplace=False)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=256, out_features=2925, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tra = Transformers(trainset.input_lang.n_words, trainset.output_lang.n_words, n_blocks=3, n_features=256, n_heads=16, n_hidden=1024)\n",
    "tra.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "    PADDING_VALUE = 0\n",
    "    num_epochs = 2\n",
    "\n",
    "    optimizer = torch.optim.Adam(tra.parameters(), lr=0.001)\n",
    "    criterion = nn.NLLLoss(ignore_index=PADDING_VALUE)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        total_data = 0\n",
    "        for src_seqs, src_mask, tgt_seqs in trainloader:\n",
    "            src_seqs, src_mask, tgt_seqs = src_seqs.to(device), src_mask.to(device), tgt_seqs.to(device)\n",
    "            \n",
    "            # forward\n",
    "            outputs = tra(src_seqs, tgt_seqs, src_mask)\n",
    "            \n",
    "            # compute loss metric\n",
    "            loss = criterion(outputs.permute(0, 2, 1).to(device), tgt_seqs[1:])\n",
    "            total_loss += (loss.item() * src_seqs.shape[1])\n",
    "            total_data += src_seqs.shape[1]\n",
    "\n",
    "            # backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"epoch: {0} training loss: {1:.3f}\".format(epoch, total_loss/total_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "    torch.save(tra.state_dict(), tra_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers model loaded from: models/transformers.pth\n"
     ]
    }
   ],
   "source": [
    "if skip_training:\n",
    "    tra.load_state_dict(torch.load(tra_model_save_path, map_location=lambda storage, loc: storage))\n",
    "    print('Transformers model loaded from: {}'.format(tra_model_save_path))\n",
    "    tra.to(device)\n",
    "    tra.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tratools = TransformersTools(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate test data:\n",
      "-----------------------------\n",
      "SRC: elle rassemble du materiel pour un livre .\n",
      "TGT: she s collecting material for a book .\n",
      "OUT: she is collecting material for a book .\n",
      "\n",
      "SRC: je suis ravi que vous ayez souleve ca .\n",
      "TGT: i m glad you brought that up .\n",
      "OUT: i m glad you brought that up .\n",
      "\n",
      "SRC: nous sommes des gagneurs .\n",
      "TGT: we re winners .\n",
      "OUT: we re survivors .\n",
      "\n",
      "SRC: je suis impatiente de te voir danser .\n",
      "TGT: i m looking forward to seeing you dance .\n",
      "OUT: i m looking forward to seeing you dance .\n",
      "\n",
      "SRC: c est une tres belle fille .\n",
      "TGT: she s a really nice girl .\n",
      "OUT: she s a beauty .\n",
      "\n",
      "SRC: je ne suis pas un toxico .\n",
      "TGT: i m not a drug addict .\n",
      "OUT: i m not a drug .\n",
      "\n",
      "SRC: je suis un artiste .\n",
      "TGT: i am an artist .\n",
      "OUT: i m an artist .\n",
      "\n",
      "SRC: je ne suis pas facilement offense .\n",
      "TGT: i m not easily offended .\n",
      "OUT: i m not easily offended .\n",
      "\n",
      "SRC: elle est aimee de ses amies .\n",
      "TGT: she s loved by her friends .\n",
      "OUT: she is deaf friends with her friends .\n",
      "\n",
      "SRC: je suis le professeur .\n",
      "TGT: i m the teacher .\n",
      "OUT: i am the teacher .\n",
      "\n",
      "SRC: tu n es pas de mes amis .\n",
      "TGT: you re no friend of mine .\n",
      "OUT: you re no friend of mine .\n",
      "\n",
      "SRC: elles sont en train de danser .\n",
      "TGT: they re dancing .\n",
      "OUT: they re dancing .\n",
      "\n",
      "SRC: c est un expert du lancer de couteaux .\n",
      "TGT: he s an expert at throwing knives .\n",
      "OUT: he is a potential kabuki drama .\n",
      "\n",
      "SRC: ils ne me suivent pas .\n",
      "TGT: they re not following me .\n",
      "OUT: they re not paying .\n",
      "\n",
      "SRC: elle est plus vieille que lui .\n",
      "TGT: she s older than him .\n",
      "OUT: she s older than him .\n",
      "\n",
      "SRC: ils sont partis .\n",
      "TGT: they re gone .\n",
      "OUT: they re gone .\n",
      "\n",
      "SRC: je suis ravi que tu aies souleve ca .\n",
      "TGT: i m glad you brought that up .\n",
      "OUT: i m glad you brought that up .\n",
      "\n",
      "SRC: nous ne sommes pas coupables .\n",
      "TGT: we re not guilty .\n",
      "OUT: we re not guilty .\n",
      "\n",
      "SRC: vous vous etes trompe d avion .\n",
      "TGT: you are on the wrong plane .\n",
      "OUT: you are mistaken child .\n",
      "\n",
      "SRC: je reflechis .\n",
      "TGT: i m thinking .\n",
      "OUT: i m considering resigning .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Translate test data:')\n",
    "print('-----------------------------')\n",
    "src_seqs, src_mask, tgt_seqs = next(iter(testloader))\n",
    "out_seqs = tratools.translate(tra, src_seqs, src_mask)\n",
    "\n",
    "for i in random.sample(range(0, 64), 20):\n",
    "    print('SRC:', tratools.seq_to_string(src_seqs[:,i], testset.input_lang))\n",
    "    print('TGT:', tratools.seq_to_string(tgt_seqs[1:,i], testset.output_lang))\n",
    "    print('OUT:', tratools.seq_to_string(out_seqs[:,i], testset.output_lang))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score on training data: 95.7484686427289\n",
      "BLEU score on test data: 58.79185315508608\n"
     ]
    }
   ],
   "source": [
    "score = tratools.compute_bleu_score(tra, trainloader, trainset.output_lang)\n",
    "print(f'BLEU score on training data: {score*100}')\n",
    "score = tratools.compute_bleu_score(tra, testloader, trainset.output_lang)\n",
    "print(f'BLEU score on test data: {score*100}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_projs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
